{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASrxW6UOqLRz",
        "outputId": "2e0b880c-41ca-49e1-e034-66ea3c738f3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observation Space Shape: (103,)\n",
            "\n",
            "Running simulation...\n",
            "Step 0: Torque Disturbances: [0. 0. 0. 0. 0.]\n",
            "Step 1: Torque Disturbances: [0. 0. 0. 0. 0.]\n",
            "Step 2: Torque Disturbances: [0. 0. 0. 0. 0.]\n",
            "Step 3: Torque Disturbances: [0. 0. 0. 0. 0.]\n",
            "Step 4: Torque Disturbances: [0. 0. 0. 0. 0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gymnasium/spaces/box.py:236: UserWarning: \u001b[33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64\u001b[0m\n",
            "  gym.logger.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/gymnasium/spaces/box.py:306: UserWarning: \u001b[33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64\u001b[0m\n",
            "  gym.logger.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "from collections import deque\n",
        "\n",
        "class MultivariateHawkesPendulum(gym.Wrapper):\n",
        "    \"\"\"\n",
        "    Pendulum environment with N correlated external disturbance sources.\n",
        "    The disturbances follow a Multivariate Hawkes Process.\n",
        "    \"\"\"\n",
        "    def __init__(self, env, num_sources=5, history_len=20, decay_rate=0.5):\n",
        "        super().__init__(env)\n",
        "        self.num_sources = num_sources\n",
        "        self.history_len = history_len\n",
        "        self.decay = decay_rate\n",
        "\n",
        "        # --- Hawkes Process Parameters ---\n",
        "        # Base intensity (spontaneous events)\n",
        "        self.mu = np.random.uniform(0.01, 0.05, size=num_sources)\n",
        "\n",
        "        # Adjacency Matrix (The Graph Structure!)\n",
        "        # Alpha[i, j] = Influence of Event j on Event i\n",
        "        # We make a random sparse graph to make spectral analysis interesting later\n",
        "        self.adjacency = np.random.uniform(0, 0.3, size=(num_sources, num_sources))\n",
        "        mask = np.random.rand(num_sources, num_sources) > 0.7\n",
        "        self.adjacency *= mask\n",
        "        np.fill_diagonal(self.adjacency, 0.1) # Self-excitation\n",
        "\n",
        "        # State variables for the process\n",
        "        self.intensities = np.copy(self.mu)\n",
        "        self.last_events = np.zeros(num_sources) # Binary: did event happen?\n",
        "\n",
        "        # History Buffer: Stores raw event logs for the Baseline Agent\n",
        "        # Shape: (History_Len * Num_Sources)\n",
        "        self.event_history = deque(maxlen=history_len)\n",
        "        # Fill with zeros initially\n",
        "        for _ in range(history_len):\n",
        "            self.event_history.append(np.zeros(num_sources))\n",
        "\n",
        "        # Update Observation Space: [State (3)] + [Event History (N*T)]\n",
        "        base_low = self.env.observation_space.low\n",
        "        base_high = self.env.observation_space.high\n",
        "\n",
        "        # Events are 0 or 1, but we allow range for flexibility\n",
        "        history_low = np.zeros(num_sources * history_len)\n",
        "        history_high = np.ones(num_sources * history_len)\n",
        "\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=np.concatenate([base_low, history_low]),\n",
        "            high=np.concatenate([base_high, history_high]),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "\n",
        "    def _step_hawkes(self):\n",
        "        \"\"\"\n",
        "        Updates the Multivariate Hawkes Process.\n",
        "        System Dynamics:\n",
        "        1. Intensity_t = mu + sum(Alpha * Intensity_{t-1} * decay) + Jump from last event\n",
        "        \"\"\"\n",
        "        # Simple discrete-time decay approximation\n",
        "        # Past influence decays\n",
        "        self.intensities = self.mu + (self.intensities - self.mu) * np.exp(-self.decay)\n",
        "\n",
        "        # Excitation: If event j happened last step, intensity i increases by Alpha[i, j]\n",
        "        excitation = self.adjacency @ self.last_events\n",
        "        self.intensities += excitation\n",
        "\n",
        "        # Stochastic Event Generation (Bernoulli based on intensity)\n",
        "        # Clip probabilities to [0, 1]\n",
        "        probs = np.clip(self.intensities, 0, 1)\n",
        "        current_events = np.random.binomial(1, probs).astype(np.float32)\n",
        "\n",
        "        self.last_events = current_events\n",
        "        self.event_history.append(current_events)\n",
        "\n",
        "        return current_events\n",
        "\n",
        "    def step(self, action):\n",
        "        # 1. Evolve the External Process\n",
        "        events = self._step_hawkes()\n",
        "\n",
        "        # 2. Disturbance impacts the physical system (Torque)\n",
        "        # We map the 5 sources to a single scalar torque disturbance\n",
        "        # e.g., Source 0 pulls left, Source 1 pulls right, etc.\n",
        "        # Weights: [-1, -0.5, 0, 0.5, 1]\n",
        "        weights = np.linspace(-2.0, 2.0, self.num_sources)\n",
        "        external_torque = np.dot(events, weights)\n",
        "\n",
        "        # 3. Apply action + disturbance to the base environment\n",
        "        # We intercept the step to inject torque.\n",
        "        # Since Pendulum step() is closed, we use a trick: modify action\n",
        "        total_action = action + external_torque\n",
        "        total_action = np.clip(total_action, -2.0, 2.0) # Clip to env limits\n",
        "\n",
        "        obs, reward, terminated, truncated, info = self.env.step(total_action)\n",
        "\n",
        "        # 4. Augment Observation (State + History)\n",
        "        flat_history = np.array(self.event_history).flatten()\n",
        "        aug_obs = np.concatenate([obs, flat_history]).astype(np.float32)\n",
        "\n",
        "        return aug_obs, reward, terminated, truncated, info\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        obs, info = self.env.reset(**kwargs)\n",
        "\n",
        "        # Reset Hawkes Process\n",
        "        self.intensities = np.copy(self.mu)\n",
        "        self.last_events = np.zeros(self.num_sources)\n",
        "        for _ in range(self.history_len):\n",
        "            self.event_history.append(np.zeros(self.num_sources))\n",
        "\n",
        "        flat_history = np.array(self.event_history).flatten()\n",
        "        aug_obs = np.concatenate([obs, flat_history]).astype(np.float32)\n",
        "\n",
        "        return aug_obs, info\n",
        "\n",
        "# --- Verification Script ---\n",
        "if __name__ == \"__main__\":\n",
        "    # Create the environment\n",
        "    base_env = gym.make(\"Pendulum-v1\")\n",
        "    # N=5 sources, History=20 steps.\n",
        "    # Total Input Dim = 3 (pendulum) + 100 (history) = 103\n",
        "    env = MultivariateHawkesPendulum(base_env, num_sources=5, history_len=20)\n",
        "\n",
        "    obs, _ = env.reset()\n",
        "    print(f\"Observation Space Shape: {obs.shape}\") # Should be (103,)\n",
        "\n",
        "    # Run a few steps to see if it crashes\n",
        "    print(\"\\nRunning simulation...\")\n",
        "    for i in range(5):\n",
        "        action = env.action_space.sample()\n",
        "        obs, reward, done, _, _ = env.step(action)\n",
        "\n",
        "        # Check the last few elements of obs to see events\n",
        "        current_events = obs[-5:]\n",
        "        print(f\"Step {i}: Torque Disturbances: {current_events}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable-baselines3 shimmy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vae0wQFbrSaW",
        "outputId": "c5c87db0-f108-4700-d6d2-0e8bff36cd3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stable-baselines3\n",
            "  Downloading stable_baselines3-2.7.1-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting shimmy\n",
            "  Downloading Shimmy-2.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: gymnasium<1.3.0,>=0.29.1 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (1.2.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (2.9.0+cpu)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (3.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2025.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3.0,>=2.3->stable-baselines3) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3.0,>=2.3->stable-baselines3) (3.0.3)\n",
            "Downloading stable_baselines3-2.7.1-py3-none-any.whl (188 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.0/188.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Shimmy-2.0.0-py3-none-any.whl (30 kB)\n",
            "Installing collected packages: shimmy, stable-baselines3\n",
            "Successfully installed shimmy-2.0.0 stable-baselines3-2.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "\n",
        "# --- Re-paste your Environment Class Here (or import it) ---\n",
        "# (Assuming MultivariateHawkesPendulum class is defined as before)\n",
        "\n",
        "def make_env():\n",
        "    \"\"\"Helper to create the environment for the agent.\"\"\"\n",
        "    base_env = gym.make(\"Pendulum-v1\")\n",
        "    # We use the same parameters as your test\n",
        "    return MultivariateHawkesPendulum(base_env, num_sources=5, history_len=20)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 1. Create Vectorized Environment (faster training)\n",
        "    # We create 4 parallel environments to speed up data collection\n",
        "    vec_env = make_vec_env(make_env, n_envs=4)\n",
        "\n",
        "    # 2. Define the PPO Agent\n",
        "    # Policy: MlpPolicy (standard dense neural networks)\n",
        "    # verbose=1 prints training progress\n",
        "    model = PPO(\"MlpPolicy\", vec_env, verbose=1, seed=42)\n",
        "\n",
        "    # 3. Parameter Count Check (The \"Systems\" Metric)\n",
        "    # The first layer connects Input(103) -> Hidden(64).\n",
        "    # That is roughly 103 * 64 = 6,592 parameters just for the first layer!\n",
        "    policy_params = sum(p.numel() for p in model.policy.parameters() if p.requires_grad)\n",
        "    print(f\"BASELINE AGENT - Total Parameters: {policy_params:,}\")\n",
        "\n",
        "    # 4. Train\n",
        "    print(\"Starting Training (Baseline)...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train for 50,000 steps (enough for Pendulum to learn basic balance)\n",
        "    model.learn(total_timesteps=50_000)\n",
        "\n",
        "    end_time = time.time()\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training Complete. Time taken: {training_time:.2f} seconds\")\n",
        "\n",
        "    # 5. Save\n",
        "    model.save(\"baseline_ppo_pendulum\")\n",
        "    print(\"Model saved as 'baseline_ppo_pendulum.zip'\")\n",
        "\n",
        "    # 6. Quick Evaluation\n",
        "    print(\"\\nEvaluating Baseline Performance...\")\n",
        "    eval_env = make_env()\n",
        "    obs, _ = eval_env.reset()\n",
        "    total_reward = 0\n",
        "\n",
        "    for _ in range(1000):\n",
        "        action, _ = model.predict(obs, deterministic=True)\n",
        "        obs, reward, done, truncated, _ = eval_env.step(action)\n",
        "        total_reward += reward\n",
        "        if done or truncated:\n",
        "            obs, _ = eval_env.reset()\n",
        "\n",
        "    print(f\"Average Reward over 1000 steps: {total_reward/1000:.2f}\")\n",
        "    # Note: Pendulum-v1 optimal reward is around -150 to -200 per episode (200 steps).\n",
        "    # So per step, 0 is perfect, -1 is okay. -8 or lower is failing."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5V34TQLrTfe",
        "outputId": "d0024a42-a8e2-4a23-91d0-06c37bf8166d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "/usr/local/lib/python3.12/dist-packages/gymnasium/spaces/box.py:236: UserWarning: \u001b[33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64\u001b[0m\n",
            "  gym.logger.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/gymnasium/spaces/box.py:306: UserWarning: \u001b[33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64\u001b[0m\n",
            "  gym.logger.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BASELINE AGENT - Total Parameters: 21,763\n",
            "Starting Training (Baseline)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 200       |\n",
            "|    ep_rew_mean     | -1.22e+03 |\n",
            "| time/              |           |\n",
            "|    fps             | 3071      |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 2         |\n",
            "|    total_timesteps | 8192      |\n",
            "----------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -1.22e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1661        |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 9           |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001984795 |\n",
            "|    clip_fraction        | 0.0118      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.41       |\n",
            "|    explained_variance   | 0.00416     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.27e+03    |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00221    |\n",
            "|    std                  | 0.987       |\n",
            "|    value_loss           | 6.88e+03    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 200          |\n",
            "|    ep_rew_mean          | -1.19e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1514         |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 16           |\n",
            "|    total_timesteps      | 24576        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016871078 |\n",
            "|    clip_fraction        | 0.00875      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.4         |\n",
            "|    explained_variance   | 0.00619      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.42e+03     |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00187     |\n",
            "|    std                  | 0.984        |\n",
            "|    value_loss           | 6.75e+03     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 200        |\n",
            "|    ep_rew_mean          | -1.16e+03  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 1400       |\n",
            "|    iterations           | 4          |\n",
            "|    time_elapsed         | 23         |\n",
            "|    total_timesteps      | 32768      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00290092 |\n",
            "|    clip_fraction        | 0.0153     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.39      |\n",
            "|    explained_variance   | 0.000632   |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.67e+03   |\n",
            "|    n_updates            | 30         |\n",
            "|    policy_gradient_loss | -0.00194   |\n",
            "|    std                  | 0.971      |\n",
            "|    value_loss           | 5.39e+03   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -1.18e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1354        |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 30          |\n",
            "|    total_timesteps      | 40960       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002902388 |\n",
            "|    clip_fraction        | 0.0163      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.38       |\n",
            "|    explained_variance   | 0.00033     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.62e+03    |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00297    |\n",
            "|    std                  | 0.958       |\n",
            "|    value_loss           | 5.35e+03    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 200          |\n",
            "|    ep_rew_mean          | -1.17e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1323         |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 37           |\n",
            "|    total_timesteps      | 49152        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021864164 |\n",
            "|    clip_fraction        | 0.0192       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.37        |\n",
            "|    explained_variance   | 9.01e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.57e+03     |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -0.00293     |\n",
            "|    std                  | 0.956        |\n",
            "|    value_loss           | 4.81e+03     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 200          |\n",
            "|    ep_rew_mean          | -1.19e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1281         |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 44           |\n",
            "|    total_timesteps      | 57344        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031536855 |\n",
            "|    clip_fraction        | 0.0193       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.37        |\n",
            "|    explained_variance   | 2.5e-05      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.24e+03     |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -0.0038      |\n",
            "|    std                  | 0.944        |\n",
            "|    value_loss           | 3.96e+03     |\n",
            "------------------------------------------\n",
            "Training Complete. Time taken: 48.66 seconds\n",
            "Model saved as 'baseline_ppo_pendulum.zip'\n",
            "\n",
            "Evaluating Baseline Performance...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gymnasium/spaces/box.py:236: UserWarning: \u001b[33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64\u001b[0m\n",
            "  gym.logger.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/gymnasium/spaces/box.py:306: UserWarning: \u001b[33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64\u001b[0m\n",
            "  gym.logger.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Reward over 1000 steps: -5.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.linalg\n",
        "\n",
        "class SpectralHawkesPendulum(MultivariateHawkesPendulum):\n",
        "    \"\"\"\n",
        "    Same physical environment, but the observation is compressed using\n",
        "    Spectral Graph Theory (Graph Fourier Transform).\n",
        "    \"\"\"\n",
        "    def __init__(self, env, num_sources=5, k_eigen=3):\n",
        "        # Initialize the parent class to get the adjacency/physics\n",
        "        super().__init__(env, num_sources=num_sources, history_len=1) # History len doesn't matter here\n",
        "\n",
        "        self.k_eigen = k_eigen\n",
        "\n",
        "        # --- Spectral Graph Theory Setup ---\n",
        "        # 1. Laplacian Matrix L = D - A\n",
        "        # (We use the unnormalized Laplacian for simplicity)\n",
        "        degrees = np.sum(self.adjacency, axis=1)\n",
        "        D = np.diag(degrees)\n",
        "        L = D - self.adjacency\n",
        "\n",
        "        # 2. Eigen Decomposition\n",
        "        # We want the eigenvectors corresponding to the *smallest* eigenvalues\n",
        "        # (Low frequency modes = smooth global trends)\n",
        "        eigenvalues, eigenvectors = scipy.linalg.eigh(L)\n",
        "\n",
        "        # 3. Sort and keep top k\n",
        "        # eigenvectors columns are the vectors\n",
        "        idx = eigenvalues.argsort()\n",
        "        self.eigenvectors = eigenvectors[:, idx]\n",
        "        self.projection_matrix = self.eigenvectors[:, :k_eigen] # Shape (N, k)\n",
        "\n",
        "        # --- Update Observation Space ---\n",
        "        # Obs = [Pendulum State (3)] + [Spectral Features (k)]\n",
        "        base_low = self.env.observation_space.low\n",
        "        base_high = self.env.observation_space.high\n",
        "\n",
        "        # Spectral features can range loosely (depends on intensities)\n",
        "        spec_low = -np.inf * np.ones(k_eigen)\n",
        "        spec_high = np.inf * np.ones(k_eigen)\n",
        "\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=np.concatenate([base_low, spec_low]),\n",
        "            high=np.concatenate([base_high, spec_high]),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "\n",
        "    def step(self, action):\n",
        "        # 1. Evolve Physics (Same as parent)\n",
        "        # We need to manually call _step_hawkes to get intensities,\n",
        "        # but we can just use the parent step and discard its observation\n",
        "        _ = self._step_hawkes()\n",
        "\n",
        "        # Calculate Force (Same as parent)\n",
        "        weights = np.linspace(-2.0, 2.0, self.num_sources)\n",
        "        external_torque = np.dot(self.last_events, weights)\n",
        "        total_action = action + external_torque\n",
        "        total_action = np.clip(total_action, -2.0, 2.0)\n",
        "\n",
        "        obs, reward, terminated, truncated, info = self.env.step(total_action)\n",
        "\n",
        "        # 2. The Spectral Transform (The \"Elegant\" part)\n",
        "        # Instead of raw events, we take the current latent intensities\n",
        "        # signal_t = [intensity_1, intensity_2, ...]\n",
        "        signal = self.intensities\n",
        "\n",
        "        # Project onto Graph Basis: GFT = U.T @ signal\n",
        "        spectral_features = self.projection_matrix.T @ signal\n",
        "\n",
        "        # 3. Construct Compact Observation\n",
        "        aug_obs = np.concatenate([obs, spectral_features]).astype(np.float32)\n",
        "\n",
        "        return aug_obs, reward, terminated, truncated, info\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        obs, info = self.env.reset(**kwargs)\n",
        "        # Reset Hawkes\n",
        "        self.intensities = np.copy(self.mu)\n",
        "        self.last_events = np.zeros(self.num_sources)\n",
        "\n",
        "        # Initial Spectral Features\n",
        "        spectral_features = self.projection_matrix.T @ self.intensities\n",
        "        aug_obs = np.concatenate([obs, spectral_features]).astype(np.float32)\n",
        "\n",
        "        return aug_obs, info"
      ],
      "metadata": {
        "id": "uqrFKWMGr_2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_spectral_env():\n",
        "    base_env = gym.make(\"Pendulum-v1\")\n",
        "    # k_eigen=3 means we only pass 3 spectral numbers!\n",
        "    return SpectralHawkesPendulum(base_env, num_sources=5, k_eigen=3)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 1. Create Env\n",
        "    vec_env_spec = make_vec_env(make_spectral_env, n_envs=4)\n",
        "\n",
        "    # 2. Create Agent\n",
        "    model_spec = PPO(\"MlpPolicy\", vec_env_spec, verbose=1, seed=42)\n",
        "\n",
        "    # 3. Parameter Count (The Systems Win)\n",
        "    # Input is now 6 (3 state + 3 spectral).\n",
        "    # First layer is 6 * 64 weights. Tiny!\n",
        "    spec_params = sum(p.numel() for p in model_spec.policy.parameters() if p.requires_grad)\n",
        "\n",
        "    print(f\"SPECTRAL AGENT - Total Parameters: {spec_params:,}\")\n",
        "    print(f\"BASELINE AGENT - Total Parameters: 21,763\")\n",
        "    print(f\"REDUCTION: {100 * (1 - spec_params/21763):.2f}% smaller\")\n",
        "\n",
        "    # 4. Train\n",
        "    print(\"Starting Training (Spectral)...\")\n",
        "    start_time = time.time()\n",
        "    model_spec.learn(total_timesteps=50_000)\n",
        "    print(f\"Training Complete. Time: {time.time() - start_time:.2f}s\")\n",
        "\n",
        "    # 5. Evaluate\n",
        "    print(\"\\nEvaluating Spectral Performance...\")\n",
        "    eval_env = make_spectral_env()\n",
        "    obs, _ = eval_env.reset()\n",
        "    total_reward = 0\n",
        "\n",
        "    for _ in range(1000):\n",
        "        action, _ = model_spec.predict(obs, deterministic=True)\n",
        "        obs, reward, done, truncated, _ = eval_env.step(action)\n",
        "        total_reward += reward\n",
        "        if done or truncated:\n",
        "            obs, _ = eval_env.reset()\n",
        "\n",
        "    print(f\"Average Reward over 1000 steps: {total_reward/1000:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekXMunYysDFV",
        "outputId": "6fe46207-68d7-41ad-cdb0-64c8bb8f12ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "SPECTRAL AGENT - Total Parameters: 9,347\n",
            "BASELINE AGENT - Total Parameters: 21,763\n",
            "REDUCTION: 57.05% smaller\n",
            "Starting Training (Spectral)...\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -1.2e+03 |\n",
            "| time/              |          |\n",
            "|    fps             | 3292     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 2        |\n",
            "|    total_timesteps | 8192     |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -1.2e+03    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1757        |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 9           |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002176545 |\n",
            "|    clip_fraction        | 0.0083      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.41       |\n",
            "|    explained_variance   | -0.00198    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.84e+03    |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.000767   |\n",
            "|    std                  | 0.989       |\n",
            "|    value_loss           | 6.76e+03    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 200          |\n",
            "|    ep_rew_mean          | -1.21e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1586         |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 15           |\n",
            "|    total_timesteps      | 24576        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027180775 |\n",
            "|    clip_fraction        | 0.0177       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.4         |\n",
            "|    explained_variance   | 0.00716      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.32e+03     |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00117     |\n",
            "|    std                  | 0.983        |\n",
            "|    value_loss           | 6.62e+03     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 200          |\n",
            "|    ep_rew_mean          | -1.19e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1456         |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 22           |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035220901 |\n",
            "|    clip_fraction        | 0.027        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | 0.0012       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.96e+03     |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00216     |\n",
            "|    std                  | 0.96         |\n",
            "|    value_loss           | 6.06e+03     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -1.2e+03    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1422        |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 28          |\n",
            "|    total_timesteps      | 40960       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004084613 |\n",
            "|    clip_fraction        | 0.0343      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.36       |\n",
            "|    explained_variance   | 0.000497    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.48e+03    |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00258    |\n",
            "|    std                  | 0.938       |\n",
            "|    value_loss           | 5.34e+03    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 200          |\n",
            "|    ep_rew_mean          | -1.16e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1382         |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 35           |\n",
            "|    total_timesteps      | 49152        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024396922 |\n",
            "|    clip_fraction        | 0.0132       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.35        |\n",
            "|    explained_variance   | 0.000215     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.61e+03     |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -0.00145     |\n",
            "|    std                  | 0.925        |\n",
            "|    value_loss           | 4.85e+03     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 200          |\n",
            "|    ep_rew_mean          | -1.14e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1362         |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 42           |\n",
            "|    total_timesteps      | 57344        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029121027 |\n",
            "|    clip_fraction        | 0.0143       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.34        |\n",
            "|    explained_variance   | 0.000108     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.28e+03     |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -0.000572    |\n",
            "|    std                  | 0.923        |\n",
            "|    value_loss           | 3.61e+03     |\n",
            "------------------------------------------\n",
            "Training Complete. Time: 46.20s\n",
            "\n",
            "Evaluating Spectral Performance...\n",
            "Average Reward over 1000 steps: -5.63\n"
          ]
        }
      ]
    }
  ]
}